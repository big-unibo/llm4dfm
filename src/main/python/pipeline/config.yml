use: 'import'

model_import:
  name: 'llama-2'
  key: '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' # huggingface key
  # pretrained: true
  temperature: 0.7 # not using at the moment TODO check if it's supported
  tokenizer:
    name: 'llama-2'
  quantization: true
  #training:
  #  output_dir: ''
  #  epochs: ''
  #  save_steps: ''


model_api:
  name: 'gpt-3.5-turbo'
  key: '' # legacy only
  max_tokens: ''
  role: 'user'
  n_responses: 1
  temperature: 0.7
  stop:

exercise:
  name: 'exercise-2.3-original'
  prompt_version: 'v1'

debug: false
